# ğŸ¤– Machine Learning Training Repository

Welcome to the repository for hands-on Machine Learning training! This repository contains Jupyter notebooks and resources for **all major supervised and unsupervised learning algorithms**, aimed at helping learners and practitioners master core ML concepts through practical implementation.

---

## ğŸ¯ Objectives

- Build a complete, organized collection of ML algorithms.
- Implement both **supervised** and **unsupervised** models from scratch and using `scikit-learn`.
- Evaluate models using appropriate metrics and visualization tools.
- Provide a foundation for academic use, interviews, and real-world ML projects.

---

## ğŸ“ Repository Structure (Planned)

---
machine-learning-training/
â”‚
â”œâ”€â”€ supervised/
â”‚   â”œâ”€â”€ regression/
â”‚   â”‚   â”œâ”€â”€ linear_regression.ipynb
â”‚   â”‚   â”œâ”€â”€ ridge_lasso_regression.ipynb
â”‚   â”‚   â””â”€â”€ decision_tree_regression.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ logistic_regression.ipynb
â”‚   â”‚   â”œâ”€â”€ knn_classification.ipynb
â”‚   â”‚   â”œâ”€â”€ svm.ipynb
â”‚   â”‚   â”œâ”€â”€ naive_bayes.ipynb
â”‚   â”‚   â””â”€â”€ random_forest_classification.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ ensemble/
â”‚       â”œâ”€â”€ gradient_boosting.ipynb
â”‚       â”œâ”€â”€ xgboost.ipynb
â”‚       â””â”€â”€ voting_bagging.ipynb
â”‚
â”œâ”€â”€ unsupervised/
â”‚   â”œâ”€â”€ clustering/
â”‚   â”‚   â”œâ”€â”€ kmeans_clustering.ipynb
â”‚   â”‚   â”œâ”€â”€ hierarchical_clustering.ipynb
â”‚   â”‚   â””â”€â”€ dbscan.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ dimensionality_reduction/
â”‚   â”‚   â”œâ”€â”€ pca.ipynb
â”‚   â”‚   â””â”€â”€ t_sne.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ anomaly_detection/
â”‚       â”œâ”€â”€ isolation_forest.ipynb
â”‚       â””â”€â”€ one_class_svm.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (datasets used in notebooks)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
---
## ğŸ“š Topics Covered

### âœ… Supervised Learning
- **Regression:** Linear, Ridge, Lasso, Decision Tree, Random Forest
- **Classification:** Logistic Regression, KNN, SVM, Naive Bayes, Ensemble methods (Bagging, Boosting)

### ğŸ” Unsupervised Learning
- **Clustering:** K-Means, DBSCAN, Agglomerative Clustering
- **Dimensionality Reduction:** PCA, t-SNE
- **Anomaly Detection:** Isolation Forest, One-Class SVM

---





